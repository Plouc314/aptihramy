{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import re\n",
    "pl.Config.set_tbl_rows(100)  \n",
    "\n",
    "csv_path = \"../../data/csv_raw\"\n",
    "cleaned_csv_path =\"../../data/csv_cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1813_part1.csv: 35\n",
      "1805.csv: 39\n",
      "1808.csv: 39\n",
      "1810.csv: 39\n",
      "1806.csv: 39\n",
      "1807.csv: 39\n",
      "1809.csv: 39\n",
      "1813_part2.csv: 47\n",
      "1895.csv: 52\n",
      "1849.csv: 52\n",
      "1853.csv: 52\n",
      "1850.csv: 52\n",
      "1854.csv: 52\n",
      "1856.csv: 52\n",
      "1851.csv: 52\n",
      "1852.csv: 52\n",
      "1857.csv: 52\n",
      "1858.csv: 52\n",
      "1843.csv: 53\n",
      "1884.csv: 53\n",
      "1861.csv: 53\n",
      "1865.csv: 53\n",
      "1877.csv: 53\n",
      "1870.csv: 53\n",
      "1885.csv: 53\n",
      "1874.csv: 53\n",
      "1872.csv: 53\n",
      "1832.csv: 53\n",
      "1873.csv: 53\n",
      "1866.csv: 53\n",
      "1844.csv: 53\n",
      "1846.csv: 53\n",
      "1848.csv: 53\n",
      "1845.csv: 53\n",
      "1882.csv: 53\n",
      "1835.csv: 53\n",
      "1837.csv: 53\n",
      "1860.csv: 53\n",
      "1871.csv: 53\n",
      "1847.csv: 53\n",
      "1839.csv: 53\n",
      "1841.csv: 53\n",
      "1838.csv: 53\n",
      "1878.csv: 53\n",
      "1875.csv: 53\n",
      "1869.csv: 53\n",
      "1879.csv: 53\n",
      "1876.csv: 53\n",
      "1883.csv: 53\n",
      "1867.csv: 53\n",
      "1862.csv: 53\n",
      "1836.csv: 53\n",
      "1863.csv: 53\n",
      "1840.csv: 53\n",
      "1868.csv: 53\n",
      "1842.csv: 53\n",
      "1864.csv: 53\n",
      "1880.csv: 53\n",
      "1881.csv: 53\n",
      "1859.csv: 53\n",
      "1894.csv: 58\n",
      "1896.csv: 58\n",
      "1893.csv: 58\n",
      "1897.csv: 58\n",
      "1888.csv: 58\n",
      "1889.csv: 58\n",
      "1890.csv: 58\n",
      "1891.csv: 58\n",
      "1892.csv: 58\n",
      "1887.csv: 58\n",
      "1886.csv: 58\n",
      "1898.csv: 58\n",
      "1855.csv: 82\n"
     ]
    }
   ],
   "source": [
    "def show_nb_columns_per_file(csv_folder_path: str):\n",
    "    counts = {}\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    \n",
    "    for filename in csv_filenames:\n",
    "        file_path = os.path.join(csv_folder_path, filename)\n",
    "\n",
    "        df = pl.read_csv(file_path, infer_schema=False)\n",
    "        counts[filename] = len(df.columns)\n",
    "\n",
    "\n",
    "    # Sort files by number of columns\n",
    "    sorted_counts = sorted(counts.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Print results\n",
    "    for filename, column_count in sorted_counts:\n",
    "        print(f\"{filename}: {column_count}\")\n",
    "\n",
    "# Call the function with the CSV folder path\n",
    "show_nb_columns_per_file(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect match: \n",
      " - nom_rue\n",
      " - nom_rue_htr_corr\n",
      " - nom_rue_norm\n",
      " - no_maison\n",
      " - chef_prenom\n",
      " - chef_prenom_htr_corr\n",
      " - chef_prenom_norm\n",
      " - chef_nom\n",
      " - chef_nom_htr_corr\n",
      " - chef_nom_norm\n",
      " - chef_origine\n",
      " - chef_origine_htr_corr\n",
      " - chef_origine_norm\n",
      " - chef_vocation\n",
      " - chef_vocation_htr_corr\n",
      " - chef_vocation_norm\n",
      " - observations\n",
      " - Page\n",
      "\n",
      "Only partial match\n",
      " - proprietaire_nom: 60\n",
      " - proprietaire_nom_corr: 57\n",
      " - proprietaire_nom_htr_corr: 60\n",
      " - proprietaire_nom_norm: 60\n",
      " - chef_nom_corr: 69\n",
      " - chef_annee_naissance: 60\n",
      " - epouse_nom: 70\n",
      " - epouse_nom_corr: 66\n",
      " - epouse_nom_htr_corr: 70\n",
      " - epouse_nom_norm: 70\n",
      " - epouse_annee_naissance: 60\n",
      " - enfants_dans_la_commune_prenom: 30\n",
      " - enfants_dans_la_commune_prenom_htr_corr: 30\n",
      " - enfants_dans_la_commune_prenom_norm: 30\n",
      " - enfants_annee_naissance: 53\n",
      " - chef_origine_corr: 69\n",
      " - chef_annee_arrivee: 23\n",
      " - chef_vocation_top_terms: 72\n",
      " - chef_recepisse: 53\n",
      " - pensionnaires_prenom: 66\n",
      " - pensionnaires_prenom_htr_corr: 66\n",
      " - pensionnaires_prenom_norm: 66\n",
      " - pensionnaires_nom: 66\n",
      " - pensionnaires_nom_corr: 63\n",
      " - pensionnaires_nom_htr_corr: 66\n",
      " - pensionnaires_nom_norm: 66\n",
      " - pensionnaires_origine: 66\n",
      " - pensionnaires_origine_corr: 63\n",
      " - pensionnaires_origine_htr_corr: 66\n",
      " - pensionnaires_origine_norm: 66\n",
      " - pensionnaires_condition: 66\n",
      " - pensionnaires_condition_top_terms: 65\n",
      " - pensionnaires_condition_htr_corr: 66\n",
      " - pensionnaires_condition_norm: 66\n",
      " - pensionnaires_recepisse: 53\n",
      " - epouse_nom_prenom: 3\n",
      " - epouse_nom_prenom_corr: 3\n",
      " - epouse_nom_prenom_htr_corr: 3\n",
      " - epouse_nom_prenom_norm: 3\n",
      " - enfants_chez_parents_prenom: 36\n",
      " - enfants_chez_parents_prenom_htr_corr: 36\n",
      " - enfants_chez_parents_prenom_norm: 36\n",
      " - pensionnaires_annee_naissance: 27\n",
      " - proprietaire_nom_adresse: 13\n",
      " - proprietaire_nom_adresse_htr_corr: 13\n",
      " - proprietaire_nom_adresse_norm: 13\n",
      " - chef_date_naissance_3: 11\n",
      " - epouse_prenom: 13\n",
      " - epouse_prenom_htr_corr: 13\n",
      " - epouse_prenom_norm: 13\n",
      " - epouse_date_naissance_3: 11\n",
      " - chef_permis: 13\n",
      " - enfants_date_naissance_3: 11\n",
      " - enfants_profession: 13\n",
      " - enfants_permis: 13\n",
      " - pensionnaires_date_naissance_3: 11\n",
      " - pensionnaires_permis: 13\n",
      " - proprietaire_nom_adresse_corr: 12\n",
      " - fils_prenom: 7\n",
      " - fils_annee_naissance: 7\n",
      " - filles_prenom: 7\n",
      " - filles_annee_naissance: 7\n",
      " - nb_domestiques: 7\n",
      " - nb_ouvriers: 7\n",
      " - nb_pensionnaires: 7\n",
      " - erreur_ligne: 1\n",
      " - division: 1\n",
      " - nom_rue_line_corr: 1\n",
      " - no_maison_line_corr: 1\n",
      " - no_maison_htr_corr: 1\n",
      " - proprietaire_nom_line_corr: 1\n",
      " - proprietaire_nom_remarques: 1\n",
      " - chef_prenom_line_corr: 1\n",
      " - chef_prenom_remarques: 1\n",
      " - chef_nom_line_corr: 1\n",
      " - chef_nom_remarque: 1\n",
      " - chef_annee_naissance_line_corr: 1\n",
      " - chef_annee_naissance_htr_corr: 1\n",
      " - chef_annee_naissance_norm: 1\n",
      " - epouse_nom_line_corr: 1\n",
      " - epouse_nom_remarques: 1\n",
      " - epouse_annee_naissance_line_corr: 1\n",
      " - epouse_annee_naissance_htr_corr: 1\n",
      " - epouse_annee_naissance_norm: 1\n",
      " - enfants_dans_la_commune_prenom_line_corr: 1\n",
      " - enfants_dans_la_commune_prenom_remarque: 1\n",
      " - enfants_annee_naissance_line_corr: 1\n",
      " - enfants_annee_naissance_htr_corr: 1\n",
      " - enfants_annee_naissance_norm: 1\n",
      " - chef_origine_line_corr: 1\n",
      " - chef_origine_remarques: 1\n",
      " - chef_vocation_line_corr: 1\n",
      " - chef_vocation_remarques: 1\n",
      " - chef_recepisse_line_corr: 1\n",
      " - pensionnaires_prenom_line_corr: 1\n",
      " - pensionnaires_prenom_remarques: 1\n",
      " - pensionnaires_nom_line_corr: 1\n",
      " - pensionnaires_nom_remarques: 1\n",
      " - pensionnaires_origine_line_corr: 1\n",
      " - pensionnaires_origine_remarques: 1\n",
      " - pensionnaires_condition_line_corr: 1\n",
      " - pensionnaires_recepisse_line_corr: 1\n",
      " - observations_line_corr: 1\n",
      " - chef_date_naissance_1: 2\n",
      " - epouse_date_naissance_1: 2\n",
      " - enfants_date_naissance_1: 2\n",
      " - pensionnaires_date_naissance_1: 2\n"
     ]
    }
   ],
   "source": [
    "def get_perfect_match_columns(csv_folder_path: str):\n",
    "    counts = {}\n",
    "\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    for filename in csv_filenames:\n",
    "        # Polar can infer types but as the columns may not be clean we force polar to read every column as string\n",
    "        df = pl.read_csv(f\"{csv_folder_path}/{filename}\", infer_schema=False)\n",
    "\n",
    "        for col in df.columns:\n",
    "            counts.setdefault(col, [])\n",
    "            counts[col].append(filename)\n",
    "    \n",
    "    length = len(csv_filenames)\n",
    "    return [col for col, files in counts.items() if len(files) == length]\n",
    "            \n",
    "def show_columns(csv_folder_path: str):\n",
    "    counts = {}\n",
    "\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    for filename in csv_filenames:\n",
    "        # Polar can infer types but as the columns may not be clean we force polar to read every column as string\n",
    "        df = pl.read_csv(f\"{csv_folder_path}/{filename}\", infer_schema=False)\n",
    "\n",
    "        for col in df.columns:\n",
    "            counts.setdefault(col, [])\n",
    "            counts[col].append(filename)\n",
    "    \n",
    "    length = len(csv_filenames)\n",
    "    print(\"Perfect match: \")\n",
    "    for col, files in counts.items():\n",
    "        if len(files) == length:\n",
    "            print(f\" - {col}\")\n",
    "\n",
    "    print(\"\\nOnly partial match\")\n",
    "    for col, files in counts.items():\n",
    "        if len(files) != length:\n",
    "            print(f\" - {col}: {len(files)}\")\n",
    "\n",
    "\n",
    "show_columns(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1884.csv', '1885.csv', '1883.csv']\n",
      "['1843.csv', '1895.csv', '1861.csv', '1865.csv', '1877.csv', '1894.csv', '1870.csv', '1849.csv', '1896.csv', '1874.csv', '1872.csv', '1832.csv', '1873.csv', '1805.csv', '1866.csv', '1844.csv', '1846.csv', '1848.csv', '1845.csv', '1893.csv', '1897.csv', '1853.csv', '1850.csv', '1808.csv', '1854.csv', '1888.csv', '1813_part1.csv', '1855.csv', '1882.csv', '1835.csv', '1837.csv', '1860.csv', '1810.csv', '1871.csv', '1847.csv', '1839.csv', '1841.csv', '1838.csv', '1878.csv', '1875.csv', '1856.csv', '1869.csv', '1889.csv', '1879.csv', '1876.csv', '1851.csv', '1867.csv', '1806.csv', '1807.csv', '1852.csv', '1862.csv', '1836.csv', '1890.csv', '1857.csv', '1863.csv', '1840.csv', '1868.csv', '1842.csv', '1864.csv', '1891.csv', '1892.csv', '1880.csv', '1887.csv', '1809.csv', '1881.csv', '1858.csv', '1813_part2.csv', '1886.csv', '1859.csv', '1898.csv']\n"
     ]
    }
   ],
   "source": [
    "def filter_files_by_column(csv_folder_path: str, col_name: str, must_have: bool = True):\n",
    "    \"\"\"\n",
    "    Filters files in a folder based on whether they contain a specific column.\n",
    "    \n",
    "    :param csv_folder_path: Path to the folder containing CSV files.\n",
    "    :param col_name: Column name to check for.\n",
    "    :param must_have: If True, return files that contain the column. If False, return files that do not contain the column.\n",
    "    :return: List of filenames matching the condition.\n",
    "    \"\"\"\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    matching_files = []\n",
    "    \n",
    "    for filename in csv_filenames:\n",
    "        file_path = os.path.join(csv_folder_path, filename)\n",
    "        try:\n",
    "            df = pl.read_csv(file_path, infer_schema=False)\n",
    "            if (col_name in df.columns) == must_have:\n",
    "                matching_files.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    \n",
    "    return matching_files\n",
    "\n",
    "def show_files_with_column(csv_folder_path: str, col_name: str):\n",
    "    print(filter_files_by_column(csv_folder_path, col_name, must_have=True))\n",
    "\n",
    "def show_files_without_column(csv_folder_path: str, col_name: str):\n",
    "    print(filter_files_by_column(csv_folder_path, col_name, must_have=False))\n",
    "\n",
    "def show_years_in_common(csv_folder_path: str, col_names: list[str]):\n",
    "    if not col_names:\n",
    "        return print([])\n",
    "\n",
    "    common_files = set(filter_files_by_column(csv_folder_path, col_names[0], must_have=True))\n",
    "    for col_name in col_names[1:]:\n",
    "        common_files.intersection_update(filter_files_by_column(csv_folder_path, col_name, must_have=True))\n",
    "    \n",
    "    print(list(common_files))\n",
    "    \n",
    "# 1883, 1884, 1885 \n",
    "show_files_without_column(csv_path,\"epouse_nom\" )\n",
    "# 1883, 1884, 1885 \n",
    "show_files_with_column(csv_path, \"epouse_nom_norm\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "['1843.csv', '1861.csv', '1849.csv', '1832.csv', '1844.csv', '1846.csv', '1848.csv', '1845.csv', '1853.csv', '1850.csv', '1854.csv', '1855.csv', '1835.csv', '1837.csv', '1860.csv', '1847.csv', '1839.csv', '1841.csv', '1838.csv', '1856.csv', '1851.csv', '1852.csv', '1862.csv', '1836.csv', '1857.csv', '1840.csv', '1842.csv', '1858.csv', '1813_part2.csv', '1859.csv']\n",
      "['1884.csv', '1895.csv', '1865.csv', '1877.csv', '1894.csv', '1870.csv', '1885.csv', '1896.csv', '1874.csv', '1872.csv', '1873.csv', '1866.csv', '1893.csv', '1897.csv', '1888.csv', '1882.csv', '1871.csv', '1878.csv', '1875.csv', '1869.csv', '1889.csv', '1879.csv', '1876.csv', '1883.csv', '1867.csv', '1890.csv', '1863.csv', '1868.csv', '1864.csv', '1891.csv', '1892.csv', '1880.csv', '1887.csv', '1881.csv', '1886.csv', '1898.csv']\n",
      "['1805.csv', '1808.csv', '1813_part1.csv', '1810.csv', '1806.csv', '1807.csv', '1809.csv']\n",
      "['1805.csv', '1808.csv', '1813_part1.csv', '1810.csv', '1806.csv', '1807.csv', '1809.csv']\n"
     ]
    }
   ],
   "source": [
    "# Before manually cleaning no year has both columns => expect to be the same column but with different names\n",
    "show_years_in_common(csv_path, [\"enfants_dans_la_commune_prenom\",\"enfants_chez_parents_prenom\"] )\n",
    "show_years_in_common(csv_path, [\"enfants_dans_la_commune_prenom\", \"fils_prenom\"])\n",
    "show_years_in_common(csv_path, [\"enfants_chez_parents_prenom\", \"fils_prenom\"])\n",
    "\n",
    "show_files_with_column(csv_path, \"enfants_dans_la_commune_prenom\")\n",
    "show_files_with_column(csv_path, \"enfants_chez_parents_prenom\")\n",
    "show_files_with_column(csv_path, \"fils_prenom\")\n",
    "show_files_with_column(csv_path, \"filles_prenom\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns span all years: True\n"
     ]
    }
   ],
   "source": [
    "def columns_span_all_years(csv_folder_path: str, columns: list[str]):\n",
    "    if len(columns) == 0:\n",
    "        return False\n",
    "    \n",
    "    a = set(filter_files_by_column(csv_folder_path, columns[0], True))\n",
    "    for col in columns[1:]:\n",
    "        a.update(filter_files_by_column(csv_folder_path, col, True))\n",
    "        \n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    missing_files = []\n",
    "\n",
    "    for filename in csv_filenames:\n",
    "        if filename not in a:\n",
    "            missing_files.append(filename)\n",
    "    \n",
    "    return missing_files\n",
    "\n",
    "cols = [\"enfants_dans_la_commune_prenom\",\"enfants_chez_parents_prenom\",\"fils_prenom\"]\n",
    "print(f\"Columns span all years: {len(columns_span_all_years(csv_path, cols)) == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(csv_folder_path: str, new_folder_path: str, renaming: dict):\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    for filename in csv_filenames:\n",
    "        file_path = os.path.join(csv_folder_path, filename)\n",
    "        try:\n",
    "            df = pl.read_csv(file_path, infer_schema=False)\n",
    "            for (old_name, new_name) in renaming.items():\n",
    "                if old_name in df.columns:\n",
    "                    df = df.rename({old_name: new_name})\n",
    "                    \n",
    "            new_file_path = os.path.join(new_folder_path, filename)\n",
    "            df.write_csv(new_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            \n",
    "\n",
    "# Rename columns\n",
    "def normalize_child_columns(csv_folder_path: str, new_folder_path: str):\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    for filename in csv_filenames:\n",
    "        file_path = os.path.join(csv_folder_path, filename)\n",
    "        try:\n",
    "            df = pl.read_csv(file_path, infer_schema=False)\n",
    "            \n",
    "            if \"fils_prenom\" in df.columns and \"filles_prenom\" in df.columns:\n",
    "                fils = df[\"fils_prenom\"].fill_null(\"\")\n",
    "                filles = df[\"filles_prenom\"].fill_null(\"\")\n",
    "                df = df.with_columns(\n",
    "                    (fils + \"|\" + filles).str.strip_chars(\"|\").alias(\"enfants_chez_parents_prenom\")\n",
    "                )\n",
    "                df = df.with_columns(\n",
    "                    (fils + \"|\" + filles).str.strip_chars(\"|\").alias(\"enfants_chez_parents_prenom_htr_corr\")\n",
    "                )\n",
    "                df = df.with_columns(\n",
    "                    (fils + \"|\" + filles).str.strip_chars(\"|\").alias(\"enfants_chez_parents_prenom_norm\")\n",
    "                )\n",
    "                df = df.drop([col for col in [\"fils_prenom\", \"filles_prenom\"] if col in df.columns])\n",
    "            \n",
    "            new_file_path = os.path.join(new_folder_path, filename)\n",
    "            df.write_csv(new_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "renaming = {\n",
    "    \"enfants_dans_la_commune_prenom\":\"enfants_chez_parents_prenom\",\n",
    "    \"enfants_dans_la_commune_prenom_htr_corr\":\"enfants_chez_parents_prenom_htr_corr\",\n",
    "    \"enfants_dans_la_commune_prenom_norm\": \"enfants_chez_parents_prenom_norm\"\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be executed once\n",
    "#normalize_child_columns(csv_path, cleaned_csv_path)\n",
    "#rename_columns(cleaned_csv_path, cleaned_csv_path, renaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In years 1883, 1884 and 1885 rename the columns:\n",
    "* `epouse_nom_prenom_norm` to `epouse_nom_norm`\n",
    "* `epouse_nom_prenom` to `epouse_nom`\n",
    "* `epouse_nom_prenom_corr` to `epouse_nom_corr`\n",
    "* `epouse_nom_prenom_htr_corr`to `epouse_nom_htr_corr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {\n",
    "    \"epouse_nom_prenom_norm\":\"epouse_nom_norm\",\n",
    "    \"epouse_nom_prenom\":\"epouse_nom\",\n",
    "    \"epouse_nom_prenom_corr\": \"epouse_nom_corr\",\n",
    "    \"epouse_nom_prenom_htr_corr\":\"epouse_nom_htr_corr\"\n",
    "}\n",
    "# To be executed once\n",
    "#rename_columns(cleaned_csv_path, cleaned_csv_path, renaming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect match: \n",
      " - nom_rue\n",
      " - nom_rue_htr_corr\n",
      " - nom_rue_norm\n",
      " - no_maison\n",
      " - chef_prenom\n",
      " - chef_prenom_htr_corr\n",
      " - chef_prenom_norm\n",
      " - chef_nom\n",
      " - chef_nom_htr_corr\n",
      " - chef_nom_norm\n",
      " - epouse_nom\n",
      " - epouse_nom_htr_corr\n",
      " - epouse_nom_norm\n",
      " - enfants_chez_parents_prenom\n",
      " - enfants_chez_parents_prenom_htr_corr\n",
      " - enfants_chez_parents_prenom_norm\n",
      " - chef_origine\n",
      " - chef_origine_htr_corr\n",
      " - chef_origine_norm\n",
      " - chef_vocation\n",
      " - chef_vocation_htr_corr\n",
      " - chef_vocation_norm\n",
      " - observations\n",
      " - Page\n",
      "\n",
      "Only partial match\n",
      " - proprietaire_nom: 62\n",
      " - proprietaire_nom_corr: 58\n",
      " - proprietaire_nom_htr_corr: 62\n",
      " - proprietaire_nom_norm: 62\n",
      " - chef_nom_corr: 70\n",
      " - chef_annee_naissance: 62\n",
      " - epouse_nom_corr: 70\n",
      " - epouse_annee_naissance: 62\n",
      " - enfants_annee_naissance: 52\n",
      " - chef_origine_corr: 70\n",
      " - chef_annee_arrivee: 25\n",
      " - chef_vocation_top_terms: 74\n",
      " - chef_recepisse: 52\n",
      " - pensionnaires_prenom: 65\n",
      " - pensionnaires_prenom_htr_corr: 65\n",
      " - pensionnaires_prenom_norm: 65\n",
      " - pensionnaires_nom: 65\n",
      " - pensionnaires_nom_corr: 63\n",
      " - pensionnaires_nom_htr_corr: 65\n",
      " - pensionnaires_nom_norm: 65\n",
      " - pensionnaires_origine: 65\n",
      " - pensionnaires_origine_corr: 63\n",
      " - pensionnaires_origine_htr_corr: 65\n",
      " - pensionnaires_origine_norm: 65\n",
      " - pensionnaires_condition: 65\n",
      " - pensionnaires_condition_top_terms: 64\n",
      " - pensionnaires_condition_htr_corr: 65\n",
      " - pensionnaires_condition_norm: 65\n",
      " - pensionnaires_recepisse: 52\n",
      " - pensionnaires_annee_naissance: 27\n",
      " - proprietaire_nom_adresse: 13\n",
      " - proprietaire_nom_adresse_htr_corr: 13\n",
      " - proprietaire_nom_adresse_norm: 13\n",
      " - chef_date_naissance_3: 11\n",
      " - epouse_prenom: 13\n",
      " - epouse_prenom_htr_corr: 13\n",
      " - epouse_prenom_norm: 13\n",
      " - epouse_date_naissance_3: 11\n",
      " - chef_permis: 13\n",
      " - enfants_date_naissance_3: 11\n",
      " - enfants_profession: 13\n",
      " - enfants_permis: 13\n",
      " - pensionnaires_date_naissance_3: 11\n",
      " - pensionnaires_permis: 13\n",
      " - proprietaire_nom_adresse_corr: 12\n",
      " - fils_annee_naissance: 7\n",
      " - filles_annee_naissance: 7\n",
      " - nb_domestiques: 7\n",
      " - nb_ouvriers: 7\n",
      " - nb_pensionnaires: 7\n",
      " - erreur_ligne: 1\n",
      " - division: 1\n",
      " - nom_rue_line_corr: 1\n",
      " - no_maison_line_corr: 1\n",
      " - no_maison_htr_corr: 1\n",
      " - proprietaire_nom_line_corr: 1\n",
      " - proprietaire_nom_remarques: 1\n",
      " - chef_prenom_line_corr: 1\n",
      " - chef_prenom_remarques: 1\n",
      " - chef_nom_line_corr: 1\n",
      " - chef_nom_remarque: 1\n",
      " - chef_annee_naissance_line_corr: 1\n",
      " - chef_annee_naissance_htr_corr: 1\n",
      " - chef_annee_naissance_norm: 1\n",
      " - epouse_nom_line_corr: 1\n",
      " - epouse_nom_remarques: 1\n",
      " - epouse_annee_naissance_line_corr: 1\n",
      " - epouse_annee_naissance_htr_corr: 1\n",
      " - epouse_annee_naissance_norm: 1\n",
      " - enfants_dans_la_commune_prenom_line_corr: 1\n",
      " - enfants_dans_la_commune_prenom_remarque: 1\n",
      " - enfants_annee_naissance_line_corr: 1\n",
      " - enfants_annee_naissance_htr_corr: 1\n",
      " - enfants_annee_naissance_norm: 1\n",
      " - chef_origine_line_corr: 1\n",
      " - chef_origine_remarques: 1\n",
      " - chef_vocation_line_corr: 1\n",
      " - chef_vocation_remarques: 1\n",
      " - chef_recepisse_line_corr: 1\n",
      " - pensionnaires_prenom_line_corr: 1\n",
      " - pensionnaires_prenom_remarques: 1\n",
      " - pensionnaires_nom_line_corr: 1\n",
      " - pensionnaires_nom_remarques: 1\n",
      " - pensionnaires_origine_line_corr: 1\n",
      " - pensionnaires_origine_remarques: 1\n",
      " - pensionnaires_condition_line_corr: 1\n",
      " - pensionnaires_recepisse_line_corr: 1\n",
      " - observations_line_corr: 1\n",
      " - chef_date_naissance_1: 2\n",
      " - epouse_date_naissance_1: 2\n",
      " - enfants_date_naissance_1: 2\n",
      " - pensionnaires_date_naissance_1: 2\n",
      "['1895.csv', '1813.csv', '1813_part1.csv', '1855.csv', '1813_part2.csv']\n"
     ]
    }
   ],
   "source": [
    "show_columns(cleaned_csv_path)\n",
    "show_files_without_column(cleaned_csv_path, \"epouse_nom_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns span all years: True\n",
      "['1805.csv', '1808.csv', '1813_part1.csv', '1810.csv', '1806.csv', '1807.csv', '1809.csv']\n",
      "['1805.csv', '1808.csv', '1813_part1.csv', '1810.csv', '1806.csv', '1807.csv', '1809.csv']\n"
     ]
    }
   ],
   "source": [
    "# Pensionnaires\n",
    "cols = [\"pensionnaires_nom\",\"nb_pensionnaires\"]\n",
    "print(f\"Columns span all years: {len(columns_span_all_years(csv_path, cols)) == 0}\")\n",
    "show_files_without_column(csv_path, \"pensionnaires_nom\")\n",
    "show_files_with_column(csv_path, \"nb_pensionnaires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensionnaires_nom and nb_pensionnaires span all years but they cannot be unified as nb_pensionnaires contains the number of pensionnaires and pensionnaires_nom contain their names. (1813 is a special case see below)\n",
    "\n",
    "The pensionaire_nom column can be used after the year 1813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge manually 1813_part1 and 1813_part2 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nom_rue', 'nom_rue_htr_corr', 'nom_rue_norm', 'no_maison', 'proprietaire_nom', 'proprietaire_nom_htr_corr', 'proprietaire_nom_norm', 'chef_prenom', 'chef_prenom_htr_corr', 'chef_prenom_norm', 'chef_nom', 'chef_nom_htr_corr', 'chef_nom_norm', 'chef_annee_naissance', 'epouse_nom', 'epouse_nom_htr_corr', 'epouse_nom_norm', 'epouse_annee_naissance', 'enfants_chez_parents_prenom', 'enfants_chez_parents_prenom_htr_corr', 'enfants_chez_parents_prenom_norm', 'chef_origine', 'chef_origine_htr_corr', 'chef_origine_norm', 'chef_annee_arrivee', 'chef_vocation', 'chef_vocation_top_terms', 'chef_vocation_htr_corr', 'chef_vocation_norm', 'observations', 'Page']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def show_columns_in_common(csv_path1: str, csv_path2: str):\n",
    "    df1 = pl.read_csv(csv_path1, infer_schema=False)\n",
    "    df2 = pl.read_csv(csv_path2, infer_schema=False)\n",
    "\n",
    "    print([col for col in df1.columns if col in df2.columns])\n",
    "    \n",
    "        \n",
    "\n",
    "def show_columns_not_in_common(csv_path1: str, csv_path2: str):\n",
    "    df1 = pl.read_csv(csv_path1, infer_schema=False)\n",
    "    df2 = pl.read_csv(csv_path2, infer_schema=False)\n",
    "\n",
    "    print([col for col in df1.columns if col not in df2.columns])\n",
    "    print([col for col in df2.columns if col not in df1.columns])\n",
    "\n",
    "show_columns_in_common(\"../../data/csv_cleaned/1813_part1.csv\", \"../../data/csv_cleaned/1813_part2.csv\")   \n",
    "show_columns_not_in_common(\"../../data/csv_cleaned/1813_part1.csv\", \"../../data/csv_cleaned/1813_part2.csv\")   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the nb_pensionnaires column contain the first and second name of the pensionaire so the pensionnaires_prenom and pensionnaires_nom could be recreated, but for simplicity the columns were removed.\n",
    "\n",
    "Manually delete from 1813_part1.csv:\n",
    "* fils_annee_naissance\n",
    "* filles_annee_naissance\n",
    "* nb_domestiques\n",
    "* nb_ouvriers\n",
    "* nb_pensionnaires \n",
    "\n",
    "Maunally added in 1813_part1.csv \n",
    "* enfants_dans_la_commune_prenom_htr_corr\n",
    "* enfants_dans_la_commune_prenom_norm\n",
    "\n",
    "Manually deleted:\n",
    "* enfants_annee_naissance \n",
    "* chef_recepisse \n",
    "* pensionnaires_prenom\n",
    "* pensionnaires_prenom_htr_corr\n",
    "* pensionnaires_prenom_norm\n",
    "* pensionnaires_nom\n",
    "* pensionnaires_nom_htr_corr\n",
    "* pensionnaires_nom_norm\n",
    "* pensionnaires_origine\n",
    "* pensionnaires_origine_htr_corr\n",
    "* pensionnaires_origine_norm\n",
    "* pensionnaires_condition\n",
    "* pensionnaires_condition_top_terms\n",
    "* pensionnaires_condition_htr_corr\n",
    "* pensionnaires_condition_norm\n",
    "* pensionnaires_recepisse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In memory data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect match: \n",
      " - nom_rue\n",
      " - nom_rue_htr_corr\n",
      " - nom_rue_norm\n",
      " - no_maison\n",
      " - chef_prenom\n",
      " - chef_prenom_htr_corr\n",
      " - chef_prenom_norm\n",
      " - chef_nom\n",
      " - chef_nom_htr_corr\n",
      " - chef_nom_norm\n",
      " - epouse_nom\n",
      " - epouse_nom_htr_corr\n",
      " - epouse_nom_norm\n",
      " - enfants_chez_parents_prenom\n",
      " - enfants_chez_parents_prenom_htr_corr\n",
      " - enfants_chez_parents_prenom_norm\n",
      " - chef_origine\n",
      " - chef_origine_htr_corr\n",
      " - chef_origine_norm\n",
      " - chef_vocation\n",
      " - chef_vocation_htr_corr\n",
      " - chef_vocation_norm\n",
      " - observations\n",
      " - Page\n",
      "\n",
      "Only partial match\n",
      " - proprietaire_nom: 62\n",
      " - proprietaire_nom_corr: 58\n",
      " - proprietaire_nom_htr_corr: 62\n",
      " - proprietaire_nom_norm: 62\n",
      " - chef_nom_corr: 70\n",
      " - chef_annee_naissance: 62\n",
      " - epouse_nom_corr: 70\n",
      " - epouse_annee_naissance: 62\n",
      " - enfants_annee_naissance: 52\n",
      " - chef_origine_corr: 70\n",
      " - chef_annee_arrivee: 25\n",
      " - chef_vocation_top_terms: 74\n",
      " - chef_recepisse: 52\n",
      " - pensionnaires_prenom: 65\n",
      " - pensionnaires_prenom_htr_corr: 65\n",
      " - pensionnaires_prenom_norm: 65\n",
      " - pensionnaires_nom: 65\n",
      " - pensionnaires_nom_corr: 63\n",
      " - pensionnaires_nom_htr_corr: 65\n",
      " - pensionnaires_nom_norm: 65\n",
      " - pensionnaires_origine: 65\n",
      " - pensionnaires_origine_corr: 63\n",
      " - pensionnaires_origine_htr_corr: 65\n",
      " - pensionnaires_origine_norm: 65\n",
      " - pensionnaires_condition: 65\n",
      " - pensionnaires_condition_top_terms: 64\n",
      " - pensionnaires_condition_htr_corr: 65\n",
      " - pensionnaires_condition_norm: 65\n",
      " - pensionnaires_recepisse: 52\n",
      " - pensionnaires_annee_naissance: 27\n",
      " - proprietaire_nom_adresse: 13\n",
      " - proprietaire_nom_adresse_htr_corr: 13\n",
      " - proprietaire_nom_adresse_norm: 13\n",
      " - chef_date_naissance_3: 11\n",
      " - epouse_prenom: 13\n",
      " - epouse_prenom_htr_corr: 13\n",
      " - epouse_prenom_norm: 13\n",
      " - epouse_date_naissance_3: 11\n",
      " - chef_permis: 13\n",
      " - enfants_date_naissance_3: 11\n",
      " - enfants_profession: 13\n",
      " - enfants_permis: 13\n",
      " - pensionnaires_date_naissance_3: 11\n",
      " - pensionnaires_permis: 13\n",
      " - proprietaire_nom_adresse_corr: 12\n",
      " - fils_annee_naissance: 7\n",
      " - filles_annee_naissance: 7\n",
      " - nb_domestiques: 7\n",
      " - nb_ouvriers: 7\n",
      " - nb_pensionnaires: 7\n",
      " - erreur_ligne: 1\n",
      " - division: 1\n",
      " - nom_rue_line_corr: 1\n",
      " - no_maison_line_corr: 1\n",
      " - no_maison_htr_corr: 1\n",
      " - proprietaire_nom_line_corr: 1\n",
      " - proprietaire_nom_remarques: 1\n",
      " - chef_prenom_line_corr: 1\n",
      " - chef_prenom_remarques: 1\n",
      " - chef_nom_line_corr: 1\n",
      " - chef_nom_remarque: 1\n",
      " - chef_annee_naissance_line_corr: 1\n",
      " - chef_annee_naissance_htr_corr: 1\n",
      " - chef_annee_naissance_norm: 1\n",
      " - epouse_nom_line_corr: 1\n",
      " - epouse_nom_remarques: 1\n",
      " - epouse_annee_naissance_line_corr: 1\n",
      " - epouse_annee_naissance_htr_corr: 1\n",
      " - epouse_annee_naissance_norm: 1\n",
      " - enfants_dans_la_commune_prenom_line_corr: 1\n",
      " - enfants_dans_la_commune_prenom_remarque: 1\n",
      " - enfants_annee_naissance_line_corr: 1\n",
      " - enfants_annee_naissance_htr_corr: 1\n",
      " - enfants_annee_naissance_norm: 1\n",
      " - chef_origine_line_corr: 1\n",
      " - chef_origine_remarques: 1\n",
      " - chef_vocation_line_corr: 1\n",
      " - chef_vocation_remarques: 1\n",
      " - chef_recepisse_line_corr: 1\n",
      " - pensionnaires_prenom_line_corr: 1\n",
      " - pensionnaires_prenom_remarques: 1\n",
      " - pensionnaires_nom_line_corr: 1\n",
      " - pensionnaires_nom_remarques: 1\n",
      " - pensionnaires_origine_line_corr: 1\n",
      " - pensionnaires_origine_remarques: 1\n",
      " - pensionnaires_condition_line_corr: 1\n",
      " - pensionnaires_recepisse_line_corr: 1\n",
      " - observations_line_corr: 1\n",
      " - chef_date_naissance_1: 2\n",
      " - epouse_date_naissance_1: 2\n",
      " - enfants_date_naissance_1: 2\n",
      " - pensionnaires_date_naissance_1: 2\n"
     ]
    }
   ],
   "source": [
    "show_columns(cleaned_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌─────────────────────────────┬───────┬────────┐\n",
      "│ names                       ┆ dates ┆ street │\n",
      "│ ---                         ┆ ---   ┆ ---    │\n",
      "│ list[str]                   ┆ str   ┆ str    │\n",
      "╞═════════════════════════════╪═══════╪════════╡\n",
      "│ [\"Alice\", \"Bob\", \"Charlie\"] ┆ 1823  ┆ here o │\n",
      "│ [\"Francis\"]                 ┆ null  ┆ null   │\n",
      "│ [\"F\", \"de La Roche\"]        ┆ 1900  ┆ there  │\n",
      "└─────────────────────────────┴───────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(100)  \n",
    "\n",
    "def replace_entries_with_placeholder(df: pl.DataFrame, column_name: str, pattern: str) -> pl.DataFrame:\n",
    "    return df.with_columns(df[column_name].cast(pl.Utf8).str.strip_chars().str.replace_all(pattern, \"\").replace(\"\",None))\n",
    "\n",
    "def clean_non_numeric_entries(df: pl.DataFrame, column_name: str) -> pl.DataFrame:\n",
    "    return replace_entries_with_placeholder(df, column_name, r\"[^0-9.]\")\n",
    "\n",
    "def clean_dots(df:pl.DataFrame, column_name:str) -> pl.DataFrame:\n",
    "    return replace_entries_with_placeholder(df, column_name, r\"[·]\")\n",
    "\n",
    "def separated_with(\n",
    "        df: pl.DataFrame, column_name: str, separators: list[str]\n",
    "    ) -> pl.DataFrame:\n",
    "\n",
    "        # Create a regex pattern to match any of the given separators\n",
    "        pattern = \"|\".join(map(re.escape, separators))\n",
    "\n",
    "        df = df.with_columns(\n",
    "            df[column_name]\n",
    "            .cast(pl.Utf8)  \n",
    "            .str.replace_all(rf\"\\s*({pattern})\\s*\", \"|\") \n",
    "            .str.split(\"|\")  # Split into lists\n",
    "            .list.eval(pl.element().str.strip_chars()) \n",
    "        )\n",
    "        return df\n",
    "\n",
    "\n",
    "df = pl.DataFrame({\"names\": [\" Alice |  Bob  , Charlie \",\" Francis \", \" F | de La Roche\"], \"dates\":[\"          1823 \", \"·\", \"1900\"],\"street\":[\" here o        \", \"·\",\"there \"]})\n",
    "df = separated_with(df, \"names\", [\"|\",\",\"])\n",
    "df = clean_non_numeric_entries(df, \"dates\")\n",
    "df = clean_dots(df, \"street\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
