{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import re\n",
    "pl.Config.set_tbl_rows(100)  \n",
    "\n",
    "csv_raw_path = \"../../data/csv_raw\"\n",
    "csv_no_dots = \"../../data/csv_no_dots\"\n",
    "csv_cleaned_path =\"../../data/csv_cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect match: \n",
      " - nom_rue\n",
      " - nom_rue_htr_corr\n",
      " - nom_rue_norm\n",
      " - no_maison\n",
      " - chef_prenom\n",
      " - chef_prenom_htr_corr\n",
      " - chef_prenom_norm\n",
      " - chef_nom\n",
      " - chef_nom_htr_corr\n",
      " - chef_nom_norm\n",
      " - epouse_nom\n",
      " - epouse_nom_htr_corr\n",
      " - epouse_nom_norm\n",
      " - enfants_chez_parents_prenom\n",
      " - enfants_chez_parents_prenom_htr_corr\n",
      " - enfants_chez_parents_prenom_norm\n",
      " - chef_origine\n",
      " - chef_origine_htr_corr\n",
      " - chef_origine_norm\n",
      " - chef_vocation\n",
      " - chef_vocation_htr_corr\n",
      " - chef_vocation_norm\n",
      " - observations\n",
      " - Page\n",
      "\n",
      "Only partial match\n",
      " - proprietaire_nom: 59\n",
      " - proprietaire_nom_corr: 57\n",
      " - proprietaire_nom_htr_corr: 59\n",
      " - proprietaire_nom_norm: 59\n",
      " - chef_nom_corr: 69\n",
      " - chef_annee_naissance: 59\n",
      " - epouse_nom_corr: 69\n",
      " - epouse_annee_naissance: 59\n",
      " - enfants_annee_naissance: 52\n",
      " - chef_origine_corr: 69\n",
      " - chef_annee_arrivee: 22\n",
      " - chef_vocation_top_terms: 71\n",
      " - chef_recepisse: 52\n",
      " - pensionnaires_prenom: 65\n",
      " - pensionnaires_prenom_htr_corr: 65\n",
      " - pensionnaires_prenom_norm: 65\n",
      " - pensionnaires_nom: 65\n",
      " - pensionnaires_nom_corr: 63\n",
      " - pensionnaires_nom_htr_corr: 65\n",
      " - pensionnaires_nom_norm: 65\n",
      " - pensionnaires_origine: 65\n",
      " - pensionnaires_origine_corr: 63\n",
      " - pensionnaires_origine_htr_corr: 65\n",
      " - pensionnaires_origine_norm: 65\n",
      " - pensionnaires_condition: 65\n",
      " - pensionnaires_condition_top_terms: 64\n",
      " - pensionnaires_condition_htr_corr: 65\n",
      " - pensionnaires_condition_norm: 65\n",
      " - pensionnaires_recepisse: 52\n",
      " - pensionnaires_annee_naissance: 27\n",
      " - proprietaire_nom_adresse: 13\n",
      " - proprietaire_nom_adresse_htr_corr: 13\n",
      " - proprietaire_nom_adresse_norm: 13\n",
      " - chef_date_naissance_3: 11\n",
      " - epouse_prenom: 13\n",
      " - epouse_prenom_htr_corr: 13\n",
      " - epouse_prenom_norm: 13\n",
      " - epouse_date_naissance_3: 11\n",
      " - chef_permis: 13\n",
      " - enfants_date_naissance_3: 11\n",
      " - enfants_profession: 13\n",
      " - enfants_permis: 13\n",
      " - pensionnaires_date_naissance_3: 11\n",
      " - pensionnaires_permis: 13\n",
      " - proprietaire_nom_adresse_corr: 12\n",
      " - fils_annee_naissance: 6\n",
      " - filles_annee_naissance: 6\n",
      " - nb_domestiques: 6\n",
      " - nb_ouvriers: 6\n",
      " - nb_pensionnaires: 6\n",
      " - erreur_ligne: 1\n",
      " - division: 1\n",
      " - nom_rue_line_corr: 1\n",
      " - no_maison_line_corr: 1\n",
      " - no_maison_htr_corr: 1\n",
      " - proprietaire_nom_line_corr: 1\n",
      " - proprietaire_nom_remarques: 1\n",
      " - chef_prenom_line_corr: 1\n",
      " - chef_prenom_remarques: 1\n",
      " - chef_nom_line_corr: 1\n",
      " - chef_nom_remarque: 1\n",
      " - chef_annee_naissance_line_corr: 1\n",
      " - chef_annee_naissance_htr_corr: 1\n",
      " - chef_annee_naissance_norm: 1\n",
      " - epouse_nom_line_corr: 1\n",
      " - epouse_nom_remarques: 1\n",
      " - epouse_annee_naissance_line_corr: 1\n",
      " - epouse_annee_naissance_htr_corr: 1\n",
      " - epouse_annee_naissance_norm: 1\n",
      " - enfants_dans_la_commune_prenom_line_corr: 1\n",
      " - enfants_dans_la_commune_prenom_remarque: 1\n",
      " - enfants_annee_naissance_line_corr: 1\n",
      " - enfants_annee_naissance_htr_corr: 1\n",
      " - enfants_annee_naissance_norm: 1\n",
      " - chef_origine_line_corr: 1\n",
      " - chef_origine_remarques: 1\n",
      " - chef_vocation_line_corr: 1\n",
      " - chef_vocation_remarques: 1\n",
      " - chef_recepisse_line_corr: 1\n",
      " - pensionnaires_prenom_line_corr: 1\n",
      " - pensionnaires_prenom_remarques: 1\n",
      " - pensionnaires_nom_line_corr: 1\n",
      " - pensionnaires_nom_remarques: 1\n",
      " - pensionnaires_origine_line_corr: 1\n",
      " - pensionnaires_origine_remarques: 1\n",
      " - pensionnaires_condition_line_corr: 1\n",
      " - pensionnaires_recepisse_line_corr: 1\n",
      " - observations_line_corr: 1\n",
      " - chef_date_naissance_1: 2\n",
      " - epouse_date_naissance_1: 2\n",
      " - enfants_date_naissance_1: 2\n",
      " - pensionnaires_date_naissance_1: 2\n"
     ]
    }
   ],
   "source": [
    "def get_perfect_match_columns(csv_folder_path: str):\n",
    "    counts = {}\n",
    "\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    for filename in csv_filenames:\n",
    "        # Polar can infer types but as the columns may not be clean we force polar to read every column as string\n",
    "        df = pl.read_csv(f\"{csv_folder_path}/{filename}\", infer_schema=False)\n",
    "\n",
    "        for col in df.columns:\n",
    "            counts.setdefault(col, [])\n",
    "            counts[col].append(filename)\n",
    "    \n",
    "    length = len(csv_filenames)\n",
    "    return [col for col, files in counts.items() if len(files) == length]\n",
    "            \n",
    "def show_columns(csv_folder_path: str):\n",
    "    counts = {}\n",
    "\n",
    "    csv_filenames = os.listdir(csv_folder_path)\n",
    "    for filename in csv_filenames:\n",
    "        # Polar can infer types but as the columns may not be clean we force polar to read every column as string\n",
    "        df = pl.read_csv(f\"{csv_folder_path}/{filename}\", infer_schema=False)\n",
    "\n",
    "        for col in df.columns:\n",
    "            counts.setdefault(col, [])\n",
    "            counts[col].append(filename)\n",
    "    \n",
    "    length = len(csv_filenames)\n",
    "    print(\"Perfect match: \")\n",
    "    for col, files in counts.items():\n",
    "        if len(files) == length:\n",
    "            print(f\" - {col}\")\n",
    "\n",
    "    print(\"\\nOnly partial match\")\n",
    "    for col, files in counts.items():\n",
    "        if len(files) != length:\n",
    "            print(f\" - {col}: {len(files)}\")\n",
    "\n",
    "\n",
    "show_columns(csv_cleaned_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entries_with_placeholder(df: pl.DataFrame, column_name: str, pattern: str) -> pl.DataFrame:\n",
    "    return df.with_columns(df[column_name].cast(pl.Utf8).str.strip_chars().str.replace_all(pattern, \"\").replace(\"\",None))\n",
    "\n",
    "def clean_non_numeric_entries(df: pl.DataFrame, column_name: str) -> pl.DataFrame:\n",
    "    return replace_entries_with_placeholder(df, column_name, r\"[^0-9.]\")\n",
    "\n",
    "def clean_dots(df:pl.DataFrame, column_name:str) -> pl.DataFrame:\n",
    "    return replace_entries_with_placeholder(df, column_name, r\"[Â·]\")\n",
    "\n",
    "def separated_with(\n",
    "        df: pl.DataFrame, column_name: str, separators: list[str]\n",
    "    ) -> pl.DataFrame:\n",
    "\n",
    "        # Create a regex pattern to match any of the given separators\n",
    "        pattern = \"|\".join(map(re.escape, separators))\n",
    "\n",
    "        df = df.with_columns(\n",
    "            df[column_name]\n",
    "            .cast(pl.Utf8)  \n",
    "            .str.replace_all(rf\"\\s*({pattern})\\s*\", \"|\") \n",
    "            .str.split(\"|\")  # Split into lists\n",
    "            .list.eval(pl.element().str.strip_chars()) \n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3_939,)\n",
      "Series: 'enfants_chez_parents_prenom' [list[str]]\n",
      "[\n",
      "\t[\"anais allax\"]\n",
      "\t[\"emile\", \"louis\"]\n",
      "\t[\"isalette\"]\n",
      "\t[\"marie\"]\n",
      "\t[\"auguste\"]\n",
      "\tnull\n",
      "\t[\"edouard\", \"willem\"]\n",
      "\t[\"francois\"]\n",
      "\t[\"rosine\"]\n",
      "\t[\"elise\"]\n",
      "\t[\"emma\"]\n",
      "\t[\"edouard\", \"blanche\", \"emma\"]\n",
      "\t[\"elise\", \"charlotte\"]\n",
      "\tnull\n",
      "\t[\"eugene\", \"iraac\"]\n",
      "\t[\"constance\", \"francois\", \"samuel\"]\n",
      "\tnull\n",
      "\t[\"marguerite\"]\n",
      "\tnull\n",
      "\t[\"francois\", \"louis\"]\n",
      "\t[\"louisa\"]\n",
      "\t[\"marie\", \"louise\", \"louis\"]\n",
      "\t[\"francois\", \"jaques\"]\n",
      "\t[\"louis\"]\n",
      "\tnull\n",
      "\t[\"jaques\"]\n",
      "\t[\"marie\"]\n",
      "\t[\"david\"]\n",
      "\t[\"charles\"]\n",
      "\t[\"charles\"]\n",
      "\t[\"cecile\", \"david\"]\n",
      "\t[\"elisa\", \"osear\"]\n",
      "\t[\"jean\", \"louis\", \"henri\"]\n",
      "\t[\"louis\", \"eugene\"]\n",
      "\t[\"gustave\", \"charles\", \"caroline\"]\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\t[\"maurice\", \"emile\", \"henriette\"]\n",
      "\t[\"louis\", \"fanny\", \"emma\"]\n",
      "\t[\"charles\", \"armand\"]\n",
      "\t[\"marius\", \"helene\", â¦ \"auguste\"]\n",
      "\t[\"sophie\", \"fanny\", \"emma\"]\n",
      "\t[\"blanche\"]\n",
      "\t[\"elise\", \"mary\"]\n",
      "\t[\"mathilde\"]\n",
      "\t[\"louise\"]\n",
      "\t[\"sophie\", \"charles\", \"philippine\"]\n",
      "\t[\"eugenie\", \"paul\", \"elise\"]\n",
      "\tâ¦\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\t[\"louis\", \"jn emanuel\", \"susette\"]\n",
      "\t[\"emile\", \"jules\"]\n",
      "\tnull\n",
      "\t[\"auguste\", \"emile\"]\n",
      "\t[\"louise francoise\", \"jean marc\"]\n",
      "\t[\"louis\", \"david\"]\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\t[\"francois\", \"benjamin\", \"marie\"]\n",
      "\t[\"marie\"]\n",
      "\t[\"jenni\", \"louise\", â¦ \"auguste\"]\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\tnull\n",
      "\t[\"jaques\"]\n",
      "\tnull\n",
      "\tnull\n",
      "\t[\"david\", \"louis\", â¦ \"jeannette\"]\n",
      "\t[\"jenni\", \"julie\", \"jeannette\"]\n",
      "\t[\"jaques\"]\n",
      "\tnull\n",
      "\t[\"jn susanne\", \"david\", â¦ \"julie\"]\n",
      "\t[\"abram\", \"jne marguerite\"]\n",
      "\tnull\n",
      "\t[\"louis\", \"jeanne marguerite\", \"benjamin\"]\n",
      "\t[\"jean\", \"henry\", â¦ \"david\"]\n",
      "\t[\"jean jaques\", \"genni\", â¦ \"julie\"]\n",
      "\t[\"henri\", \"francois\", \"susanne nanette\"]\n",
      "\t[\"jenni\"]\n",
      "\tnull\n",
      "\tnull\n",
      "\t[\"henriette\"]\n",
      "\tnull\n",
      "\t[\"jeanne louise\", \"julie\", â¦ \"jeanne marguerite\"]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "csv_filenames = os.listdir(csv_cleaned_path)\n",
    "\n",
    "childrens = [\"enfants_chez_parents_prenom\",\n",
    " \"enfants_chez_parents_prenom_htr_corr\",\n",
    " \"enfants_chez_parents_prenom_norm\"]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in csv_filenames:\n",
    "    file_path = os.path.join(csv_cleaned_path, filename)\n",
    "    try:\n",
    "        df = pl.read_csv(file_path, infer_schema=False)\n",
    "        for col in  childrens:\n",
    "            df = separated_with(df, col, [\"|\"])\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
